[{"authors":["marcel-reinders"],"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"2a1a5c2796f9a0f99b5105cc33e1d60f","permalink":"https://cvlab-tudelft.github.io/people/marcel-reinders/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/people/marcel-reinders/","section":"authors","summary":"","tags":null,"title":"Marcel Reinders","type":"authors"},{"authors":["jan-van-gemert"],"categories":null,"content":"","date":1643527421,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1643527421,"objectID":"b2af85fedca93d0982de0d50ca39785c","permalink":"https://cvlab-tudelft.github.io/people/jan-van-gemert/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/people/jan-van-gemert/","section":"authors","summary":"","tags":null,"title":"Jan van Gemert","type":"authors"},{"authors":["xucong-zhang"],"categories":null,"content":"Research Interest: My current research is about computer vision, machine learning, and human-computer interactions. My core research interest is human-centred computing as developing techniques for sensing, understanding, and serving the human user.\nGaze estimation The task is the estimation of where the people looking from the input eye/face image. The methodology is mainly about computer vision and machine learning techniques.\nHuman-computer interaction My current research on HCI is applying the computer vision methods, such as gaze estimation, to the HCI task.\nHuman digitalization My next five years (2022-2027) research plan is to develop the talking virtual avatar that can act like a human being. The virtual avatar can be used for HCI application and human-related modelling.\nBiomechanical prior model My next ten years (2022 - 2032) research plan is to develop computer vision and machine learning tools for biology- and healthcare-related research. As the starting point, I will introduce the biomechanical prior for the human-related models.\nShort Bio: I am an assistant professor at TU Delft since August 2021. I was a postdoc researcher (2018-2021) in the Advanced Interaction Technologies Lab at ETH Zurich, led by Prof. Otmar Hilliges. I did my PhD research (2013-2018) at Max Planck Institute for Informatics (MPII) (summa cum laude) under the supervision of Prof. Andreas Bulling in Saarbruken, Germany.\n","date":1659102979,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1659102979,"objectID":"b65529db56b0913d094fb03d1d5f3a80","permalink":"https://cvlab-tudelft.github.io/people/xucong-zhang/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/people/xucong-zhang/","section":"authors","summary":"Research Interest: My current research is about computer vision, machine learning, and human-computer interactions. My core research interest is human-centred computing as developing techniques for sensing, understanding, and serving the human user.","tags":null,"title":"Xucong Zhang","type":"authors"},{"authors":["nergis-tomen"],"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"bc3258f4c96ba206793bc2ad2e7d76fb","permalink":"https://cvlab-tudelft.github.io/people/nergis-tomen/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/people/nergis-tomen/","section":"authors","summary":"","tags":null,"title":"Nergis Tömen","type":"authors"},{"authors":["hadi-jamali-rad"],"categories":null,"content":"Hadi Jamali-Rad is a lead research scientist with Shell, also a Part-Time Assistant Professor (20%) with the department of intelligent systems (INSY), the Computer Vision Lab, at TU Delft. His research interest lies in the confluence of machine learning and optimization applied to a variety of problems in computer vision, wireless (IoT) networking, and geophysics. He leads the R\u0026amp;D track of deep learning and computer vision at Shell, as well as major projects in the AI space. Prior to joining Shell, he obtained his PhD in statistical signal processing (Cum Laude) under supervision of Prof. Geert Leus at TU Delft in 2014. During his PhD, he visited CSIP at Georgia Tech (supervised by Prof. Xiaoli Ma), and STADIUS at KU Leuven (supervised by Prof. Marc Moonen and dr. Toon van Waterschoot).\nPersonal page: https://sites.google.com/view/jamalirad/\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"9ccb4a3bd16b884c19c69c2b74f4716f","permalink":"https://cvlab-tudelft.github.io/people/hadi-jamali-rad/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/people/hadi-jamali-rad/","section":"authors","summary":"Hadi Jamali-Rad is a lead research scientist with Shell, also a Part-Time Assistant Professor (20%) with the department of intelligent systems (INSY), the Computer Vision Lab, at TU Delft. His research interest lies in the confluence of machine learning and optimization applied to a variety of problems in computer vision, wireless (IoT) networking, and geophysics.","tags":null,"title":"Hadi Jamali-Rad","type":"authors"},{"authors":["robert-jan-bruintjes"],"categories":null,"content":"Third year PhD candidate in the Computer Vision lab at TU Delft, the Netherlands. I am interested in method that integrate prior knowledge about the visual domain into Deep Learning-based Computer Vision. This prior knowledge includes equivariance to geometrical transformations and signal processing best practices. I am a co-organizer of the yearly Visual Inductive Priors for Data-Efficient Deep Learning workshop, hosted at ECCV and ICCV.\n","date":1643527421,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1643527421,"objectID":"29932f6107eb093aead06ece2160a538","permalink":"https://cvlab-tudelft.github.io/people/robert-jan-bruintjes/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/people/robert-jan-bruintjes/","section":"authors","summary":"Third year PhD candidate in the Computer Vision lab at TU Delft, the Netherlands. I am interested in method that integrate prior knowledge about the visual domain into Deep Learning-based Computer Vision.","tags":null,"title":"Robert-Jan Bruintjes","type":"authors"},{"authors":["attila-lengyel"],"categories":null,"content":"Third year PhD Candidate at the Computer Vision Lab of Delft University of Technology. I’m interested in both fundamental deep learning research as well as developing computer vision technology to help tackle today’s global challenges. My main research interests include self-supervised representation learning, invariant / equivariant CNNs and color encoding in neural networks.\nBesides that, I also enjoy (kite)surfing, hiking and playing the guitar.\nIf you’re interested to collaborate, feel free to drop me an email.\n","date":1633817635,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1633817635,"objectID":"408b394be9107c079a4cfb0dca4a7c0b","permalink":"https://cvlab-tudelft.github.io/people/attila-lengyel/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/people/attila-lengyel/","section":"authors","summary":"Third year PhD Candidate at the Computer Vision Lab of Delft University of Technology. I’m interested in both fundamental deep learning research as well as developing computer vision technology to help tackle today’s global challenges.","tags":null,"title":"Attila Lengyel","type":"authors"},{"authors":["silvia-l-pintea"],"categories":null,"content":"Left TU Delft in 2021.\nHomepage: https://silvialaurapintea.github.io/\n","date":1615325726,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1615325726,"objectID":"10c3d710fa54d7500670e27aa2f53f0a","permalink":"https://cvlab-tudelft.github.io/people/silvia-l.-pintea/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/people/silvia-l.-pintea/","section":"authors","summary":"Left TU Delft in 2021.\nHomepage: https://silvialaurapintea.github.io/","tags":null,"title":"Silvia L. Pintea","type":"authors"},{"authors":["xin-liu"],"categories":null,"content":"","date":1615325726,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1615325726,"objectID":"8f6af26f33f152ceddb7334ad2667cf0","permalink":"https://cvlab-tudelft.github.io/people/xin-liu/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/people/xin-liu/","section":"authors","summary":"","tags":null,"title":"Xin Liu","type":"authors"},{"authors":["osman-semih-kayhan"],"categories":null,"content":"","date":1615281981,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1615281981,"objectID":"603eb7bbd72506174cfbe7ead1a94f23","permalink":"https://cvlab-tudelft.github.io/people/osman-semih-kayhan/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/people/osman-semih-kayhan/","section":"authors","summary":"","tags":null,"title":"Osman Semih Kayhan","type":"authors"},{"authors":["yancong-lin"],"categories":null,"content":"","date":1595098203,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1595098203,"objectID":"09bd1a4492f678a84d62ef7c06a6a08c","permalink":"https://cvlab-tudelft.github.io/people/yancong-lin/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/people/yancong-lin/","section":"authors","summary":"","tags":null,"title":"Yancong Lin","type":"authors"},{"authors":["ombretta-strafforello"],"categories":null,"content":"Since 2019, Ph.D. student in the Computer Vision lab at Delft University of Technology. My main research interest lies in automatic video understanding, with focus on complex action recognition, video summarization and video object detection. I am also interested in human-centered evaluations of deep learning systems.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"a44889352918ad22926ffb049b6d1e99","permalink":"https://cvlab-tudelft.github.io/people/ombretta-strafforello/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/people/ombretta-strafforello/","section":"authors","summary":"Since 2019, Ph.D. student in the Computer Vision lab at Delft University of Technology. My main research interest lies in automatic video understanding, with focus on complex action recognition, video summarization and video object detection.","tags":null,"title":"Ombretta Strafforello","type":"authors"},{"authors":["ziqi-wang"],"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"11291476184bee52af0ea63404e69581","permalink":"https://cvlab-tudelft.github.io/people/ziqi-wang/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/people/ziqi-wang/","section":"authors","summary":"","tags":null,"title":"Ziqi Wang","type":"authors"},{"authors":["Xucong Zhang","Seonwook Park","and Anna Maria Feit"],"categories":[],"content":"","date":1659102979,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1659102979,"objectID":"948e0bdc5e60131769b4454a80f7c77c","permalink":"https://cvlab-tudelft.github.io/publication/2021_gaze_and_applications/","publishdate":"2022-07-29T15:56:19+02:00","relpermalink":"/publication/2021_gaze_and_applications/","section":"publication","summary":"The human eye gaze is an important non-verbal cue that can unobtrusively provide information about the intention and attention of a user to enable intelligent interactive systems. Eye gaze can also be taken as input to systems as a replacement of the conventional mouse and keyboard, and can also be indicative of the cognitive state of the user. However, estimating and applying gaze in real-world applications poses significant challenges. In this chapter, we first review the development of gaze estimation methods in recent years. We especially focus on learning-based gaze estimation methods which benefit from large-scale data and deep learning methods that recently became available. Second, we discuss the challenges of using gaze estimation for real-world applications and our efforts toward making these methods easily usable for the Human-Computer Interaction community. At last, we provide two application examples, demonstrating the use of eye gaze to enable attentive and adaptive interfaces.","tags":[],"title":"Eye Gaze Estimation and Its Applications","type":"publication"},{"authors":["David W. Romero","Robert-Jan Bruintjes","Jakub M. Tomczak","Erik J. Bekkers","Mark Hoogendoorn","Jan van Gemert"],"categories":[],"content":"","date":1643527421,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1643527421,"objectID":"cdb49603fa88696470d1544bdc1bf43a","permalink":"https://cvlab-tudelft.github.io/publication/2021-flexconv/","publishdate":"2022-01-30T09:23:41+02:00","relpermalink":"/publication/2021-flexconv/","section":"publication","summary":"We provide a high bandwidth, alias-free convolutional kernel parameterization with learnable kernel size and constant parameter cost.","tags":["inductive priors"],"title":"FlexConv: Continuous Kernel Convolutions with Differentiable Kernel Sizes","type":"publication"},{"authors":["Adrian Spurr*","Aneesh Dahiya*","Xi Wang","Xucong Zhang","and Otmar Hilliges."],"categories":[],"content":"","date":1635516776,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1635516776,"objectID":"cdba4003ac9afef932e223fe8e2b3f61","permalink":"https://cvlab-tudelft.github.io/publication/2021_peclr/","publishdate":"2022-07-29T16:12:56+02:00","relpermalink":"/publication/2021_peclr/","section":"publication","summary":"","tags":[],"title":"Self-Supervised 3D Hand Pose Estimation from monocular RGB via Contrastive Learning","type":"publication"},{"authors":["Attila Lengyel","Sourav Garg","Michael Milford","Jan van Gemert"],"categories":[],"content":"","date":1633817635,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1633817635,"objectID":"a7f6b113ecf52590a6a46894f29add70","permalink":"https://cvlab-tudelft.github.io/publication/2021-zero-shot-day-night/","publishdate":"2021-10-10T00:13:55+02:00","relpermalink":"/publication/2021-zero-shot-day-night/","section":"publication","summary":"We explore the zero-shot setting for day-night domain adaptation. We cast a number of color invariant edge detectors as trainable layers in a convolutional neural network and evaluate their robustness to illumination changes.","tags":["ICCV","color invariants","domain adaptation","day-night"],"title":"Zero-Shot Day-Night Domain Adaptation with a Physics Prior","type":"publication"},{"authors":["Attila Lengyel","Jan van Gemert"],"categories":[],"content":"","date":1631227226,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1631227226,"objectID":"cf6251c884e6365de06b0bafa0a4fd06","permalink":"https://cvlab-tudelft.github.io/publication/2021-separable-gconv/","publishdate":"2021-10-10T00:40:26+02:00","relpermalink":"/publication/2021-separable-gconv/","section":"publication","summary":"We show that GConvs can be efficiently decomposed into depthwise separable convolutions while preserving equivariance properties and demonstrate improved performance and data efficiency on two datasets.","tags":["ICIP","equivariance","gconv","data efficiency"],"title":"Exploiting Learned Symmetries in Group Equivariant Convolutions","type":"publication"},{"authors":["Xin Liu","Silvia L. Pintea","Fatemeh Karimi Nejadasl","Olaf Booij","Jan van Gemert"],"categories":[],"content":"","date":1615325726,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1615325726,"objectID":"af6eb57e329c30d7c441cb32d544d215","permalink":"https://cvlab-tudelft.github.io/publication/2021-no-frame-left-behind/","publishdate":"2021-03-09T23:35:26+02:00","relpermalink":"/publication/2021-no-frame-left-behind/","section":"publication","summary":"We cluster video frames end-to-end to use all frames in action recognition.","tags":["video-understanding"],"title":"No frame left behind: Full Video Action Recognition","type":"publication"},{"authors":["Robert-Jan Bruintjes","Attila Lengyel","Marcos Baptista Rios","Osman Semih Kayhan","Jan van Gemert"],"categories":[],"content":"","date":1615281981,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1615281981,"objectID":"4c0824bc0d51e476b3716d85ced5012c","permalink":"https://cvlab-tudelft.github.io/publication/2021-vipriors-1/","publishdate":"2021-03-09T10:26:21+01:00","relpermalink":"/publication/2021-vipriors-1/","section":"publication","summary":"We present the first edition of \"VIPriors: Visual Inductive Priors for Data-Efficient Deep Learning\" challenges. We offer four data-impaired challenges to encourage data efficient solutions.","tags":["inductive priors"],"title":"VIPriors 1: Visual Inductive Priors for Data-Efficient Deep Learning Challenges","type":"publication"},{"authors":["Yufeng Zheng","Seonwook Park","Xucong Zhang","Shalini De Mello","and Otmar Hilliges"],"categories":[],"content":"","date":1607244578,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1607244578,"objectID":"9f03df6f49931228b586d9fa8e62bb1b","permalink":"https://cvlab-tudelft.github.io/publication/2020_sted/","publishdate":"2022-08-04T10:49:38+02:00","relpermalink":"/publication/2020_sted/","section":"publication","summary":"","tags":[],"title":"Self-Learning Transformations for Improving Gaze and Head Redirection","type":"publication"},{"authors":["Seonwook Park","Emre Aksan","Xucong Zhang","and Otmar Hilliges"],"categories":[],"content":"","date":1603461078,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1603461078,"objectID":"906ea68dab6ee0e142852afd29acfb27","permalink":"https://cvlab-tudelft.github.io/publication/2020_eve/","publishdate":"2022-08-05T15:51:18+02:00","relpermalink":"/publication/2020_eve/","section":"publication","summary":"","tags":[],"title":"Towards End-to-end Video-based Eye-tracking ","type":"publication"},{"authors":["Xucong Zhang","Seonwook Park","Thabo Beeler","Derek Bradley","Siyu Tang","and Otmar Hilliges"],"categories":[],"content":"","date":1603460696,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1603460696,"objectID":"fbd4b1b3fb557f6f2e00652efff4bb52","permalink":"https://cvlab-tudelft.github.io/publication/2020_eth_xgaze/","publishdate":"2022-08-05T15:44:56+02:00","relpermalink":"/publication/2020_eth_xgaze/","section":"publication","summary":"","tags":[],"title":"ETH-XGaze: A Large Scale Dataset for Gaze Estimation under Extreme Head Pose and Gaze Variation","type":"publication"},{"authors":["Xucong Zhang","Yusuke Sugano","Andreas Bulling","and Otmar Hilliges"],"categories":[],"content":"","date":1599472194,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1599472194,"objectID":"dd3ae5488ed176e48de44ab2f25a35dc","permalink":"https://cvlab-tudelft.github.io/publication/2020_regionselect/","publishdate":"2022-08-04T11:49:54+02:00","relpermalink":"/publication/2020_regionselect/","section":"publication","summary":"","tags":[],"title":"Learning-based Region Selection for End-to-End Gaze Estimation","type":"publication"},{"authors":["Yancong Lin","Silvia L. Pintea","Jan van Gemert"],"categories":[],"content":"","date":1595098203,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1595098203,"objectID":"53248486837ba72de91b53d420b70488","permalink":"https://cvlab-tudelft.github.io/publication/2020-deep-hough/","publishdate":"2020-09-11T20:50:03+02:00","relpermalink":"/publication/2020-deep-hough/","section":"publication","summary":"We add line priors through a trainable Hough transform block into a deep network.","tags":["Hough transform","inductive priors","line detection"],"title":"Deep Hough-Transform Line Priors","type":"publication"},{"authors":["Yihua Cheng","Xucong Zhang","Feng Lu","Yoichi Sato"],"categories":[],"content":"","date":1584712382,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1584712382,"objectID":"4ca8691b8a35d4e6f54a24755b06f69b","permalink":"https://cvlab-tudelft.github.io/publication/2020_asymmetry/","publishdate":"2022-08-05T15:53:02+02:00","relpermalink":"/publication/2020_asymmetry/","section":"publication","summary":"","tags":[],"title":"Gaze Estimation by Exploring Two-Eye Asymmetry","type":"publication"},{"authors":["Osman Semih Kayhan","Jan van Gemert"],"categories":[],"content":"","date":1583597647,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1583597647,"objectID":"33c3056fabefb6e8866005ef9dc68f29","permalink":"https://cvlab-tudelft.github.io/publication/2020-on-translation-invariance/","publishdate":"2020-09-07T18:14:07+02:00","relpermalink":"/publication/2020-on-translation-invariance/","section":"publication","summary":"We show we can prevent CNNs from exploiting absolute location through image boundary effects.","tags":["inductive priors","equivariance","boundary effects","image classification"],"title":"On Translation Invariance in CNNs: Convolutional Layers Can Exploit Absolute Spatial Location","type":"publication"},{"authors":["Marcel Buhler","Seonwook Park","Shalini De Mello","Xucong Zhang","and Otmar Hilliges"],"categories":[],"content":"","date":1565014064,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1565014064,"objectID":"a3d6711bb2dcd6be49d8fcbbdf916601","permalink":"https://cvlab-tudelft.github.io/publication/2019_seg2eye/","publishdate":"2022-08-05T16:07:44+02:00","relpermalink":"/publication/2019_seg2eye/","section":"publication","summary":"","tags":[],"title":"Content-Consistent Generation of Realistic Eyes with Style","type":"publication"},{"authors":["Zhe He","Adrian Spurr","Xucong Zhang","Otmar Hilliges"],"categories":[],"content":"","date":1565013949,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1565013949,"objectID":"ec9dad8148fafda6123e9575ef2e2b76","permalink":"https://cvlab-tudelft.github.io/publication/2019_gaze_redirection/","publishdate":"2022-08-05T16:05:49+02:00","relpermalink":"/publication/2019_gaze_redirection/","section":"publication","summary":"","tags":[],"title":"Photo-realistic Monocular Gaze Redirection Using Generative Adversarial Networks","type":"publication"},{"authors":["Xucong Zhang","Yusuke Sugano","and Andreas Bulling"],"categories":[],"content":"","date":1556978652,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1556978652,"objectID":"c5b7a38f1cb188e07fd977a993f8fdbb","permalink":"https://cvlab-tudelft.github.io/publication/2019_opengaze/","publishdate":"2022-08-05T16:04:12+02:00","relpermalink":"/publication/2019_opengaze/","section":"publication","summary":"","tags":[],"title":"Evaluation of Appearance-Based Methods for Gaze-Based Applications","type":"publication"},{"authors":["Xucong Zhang"],"categories":[],"content":"","date":1540908608,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1540908608,"objectID":"2c3d5dd6d4097d7e0493c1de518d11b0","permalink":"https://cvlab-tudelft.github.io/publication/2018_xucong_zhang_thesis/","publishdate":"2022-08-05T16:10:08+02:00","relpermalink":"/publication/2018_xucong_zhang_thesis/","section":"publication","summary":"","tags":[],"title":"Gaze estimation and interaction in real-world environments","type":"publication"},{"authors":["Xucong Zhang","Yusuke Sugano","and Andreas Bulling"],"categories":[],"content":"","date":1538748707,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1538748707,"objectID":"f0fdc09f5bf47b055651a2f3b1443bf0","permalink":"https://cvlab-tudelft.github.io/publication/2018_multi_device_gaze/","publishdate":"2022-08-05T16:11:47+02:00","relpermalink":"/publication/2018_multi_device_gaze/","section":"publication","summary":"","tags":[],"title":"Training Person-Specific Gaze Estimators from User Interactions with Multiple Devices","type":"publication"},{"authors":["Philipp Müller","Xucong Zhang","Michael Xuelin Huang","and Andreas Bulling"],"categories":[],"content":"","date":1528985876,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1528985876,"objectID":"059eac87ef571705fe757d3830e2fd43","permalink":"https://cvlab-tudelft.github.io/publication/2018_mueller18_etra/","publishdate":"2022-08-05T16:17:56+02:00","relpermalink":"/publication/2018_mueller18_etra/","section":"publication","summary":"","tags":[],"title":"Robust Eye Contact Detection in Natural Multi-Person Interactions Using Gaze and Speaking Behaviour","type":"publication"},{"authors":["Xucong Zhang","Yusuke Sugano","and Andreas Bulling"],"categories":[],"content":"","date":1528985761,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1528985761,"objectID":"75625e3bae2dc9de98ca9380f8ad5a6c","permalink":"https://cvlab-tudelft.github.io/publication/2018_data_normalization/","publishdate":"2022-08-05T16:16:01+02:00","relpermalink":"/publication/2018_data_normalization/","section":"publication","summary":"","tags":[],"title":"Revisiting Data Normalization for Appearance-based Gaze Estimation","type":"publication"},{"authors":["Seonwook Park","Xucong Zhang","Andreas Bulling","and Otmar Hilliges"],"categories":[],"content":"","date":1528985608,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1528985608,"objectID":"93ac1a9f9c5bf530d6460d212cdc9695","permalink":"https://cvlab-tudelft.github.io/publication/2018_landmarks-gaze/","publishdate":"2022-08-05T16:13:28+02:00","relpermalink":"/publication/2018_landmarks-gaze/","section":"publication","summary":"","tags":[],"title":"Learning to find eye region landmarks for remote gaze estimation in unconstrained settings","type":"publication"},{"authors":["Xucong Zhang","Yusuke Sugano","and Andreas Bulling"],"categories":[],"content":"","date":1508682009,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1508682009,"objectID":"f8ac534df03c6fafecf7ce722141ae98","permalink":"https://cvlab-tudelft.github.io/publication/2017_eye_contact/","publishdate":"2022-08-05T16:20:09+02:00","relpermalink":"/publication/2017_eye_contact/","section":"publication","summary":"","tags":[],"title":"Everyday Eye Contact Detection Using Unsupervised Gaze Target Discovery","type":"publication"},{"authors":["Xucong Zhang","Yusuke Sugano","and Andreas Bulling"],"categories":[],"content":"","date":1498055827,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1498055827,"objectID":"dd33567b1b70c5552452a61ed712e631","permalink":"https://cvlab-tudelft.github.io/publication/2017_fullface_gaze/","publishdate":"2022-08-05T16:37:07+02:00","relpermalink":"/publication/2017_fullface_gaze/","section":"publication","summary":"","tags":[],"title":"It’s Written All Over Your Face: Full-face Appearance-based Gaze Estimation","type":"publication"},{"authors":["Xucong Zhang","Yusuke Sugano","Mario Fritz","and Andreas Bulling"],"categories":[],"content":"","date":1483627143,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1483627143,"objectID":"90be49fdf60504120efcf60800dad705","permalink":"https://cvlab-tudelft.github.io/publication/2017_mpiigaze_tpami/","publishdate":"2022-08-05T16:39:03+02:00","relpermalink":"/publication/2017_mpiigaze_tpami/","section":"publication","summary":"","tags":[],"title":"MPIIGaze: Real-World Dataset and Deep Appearance-Based Gaze Estimation","type":"publication"},{"authors":["Yusuke Sugano","Xucong Zhang","Andreas Bulling"],"categories":[],"content":"","date":1476628893,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1476628893,"objectID":"f973cb6cf199cbc7f9a66d48ed4c3a27","permalink":"https://cvlab-tudelft.github.io/publication/2016_aggregaze/","publishdate":"2022-08-05T16:41:33+02:00","relpermalink":"/publication/2016_aggregaze/","section":"publication","summary":"","tags":[],"title":"AggreGaze: Collective Estimation of Audience Attention on Public Displays","type":"publication"},{"authors":["Daniel Pohl","Xucong Zhang","Andreas Bulling"],"categories":[],"content":"","date":1458398724,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1458398724,"objectID":"a05f4618e57efc2d0b882deb1fd804a1","permalink":"https://cvlab-tudelft.github.io/publication/2016_pohl_vr/","publishdate":"2022-08-05T16:45:24+02:00","relpermalink":"/publication/2016_pohl_vr/","section":"publication","summary":"","tags":[],"title":"Combining Eye Tracking with Optimizations for Lens Astigmatism in modern wide-angle HMDs","type":"publication"},{"authors":["Marc Tonsen","Xucong Zhang","Yusuke Sugano","Andreas Bulling"],"categories":[],"content":"","date":1457966602,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1457966602,"objectID":"52886e3d33d4d6d82a2fe795a2bc53fe","permalink":"https://cvlab-tudelft.github.io/publication/2016_lpw/","publishdate":"2022-08-05T16:43:22+02:00","relpermalink":"/publication/2016_lpw/","section":"publication","summary":"","tags":[],"title":"Labelled pupils in the wild: A dataset for studying pupil detection in unconstrained environments","type":"publication"},{"authors":["Erroll Wood","Tadas Baltrušaitis","Xucong Zhang","Yusuke Sugano","Peter Robinson","Andreas Bulling"],"categories":[],"content":"","date":1446907681,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1446907681,"objectID":"cb31d9e0aff4e6c35a29b6214e81bd9a","permalink":"https://cvlab-tudelft.github.io/publication/2015_syntheseyes/","publishdate":"2022-08-05T16:48:01+02:00","relpermalink":"/publication/2015_syntheseyes/","section":"publication","summary":"","tags":[],"title":"Rendering of eyes for eye-shape registration and gaze estimation","type":"publication"},{"authors":["Xucong Zhang","Yusuke Sugano","Mario Fritz","Andreas Bulling"],"categories":[],"content":"","date":1433515769,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1433515769,"objectID":"32115cdb07b010019523f6f0fbd92f6f","permalink":"https://cvlab-tudelft.github.io/publication/2015_mpiigaze/","publishdate":"2022-08-05T16:49:29+02:00","relpermalink":"/publication/2015_mpiigaze/","section":"publication","summary":"","tags":[],"title":"Appearance-based Gaze Estimation in the Wild","type":"publication"},{"authors":["Junjie Yan","Xucong Zhang","Zhen Lei","Shengcai Liao","and Stan Z. Li"],"categories":[],"content":"","date":1371999645,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1371999645,"objectID":"ce7a77774d25656f2d5f092536f31706","permalink":"https://cvlab-tudelft.github.io/publication/2013_multi_res_pedestrain/","publishdate":"2022-08-05T17:00:45+02:00","relpermalink":"/publication/2013_multi_res_pedestrain/","section":"publication","summary":"","tags":[],"title":"Robust multi-resolution pedestrian detection in traffic scenes","type":"publication"},{"authors":null,"categories":null,"content":"Teaching We provide various courses on computer vision at both the undergraduate and the graduate level. Specifically, we teach courses on Image Processing (B.Sc. level), Computer Vision (M.Sc. level) and Deep Learning (M.Sc. level). In addition, we supervise students at all levels in fundamental and applied research projects, several of which are performed in collaboration with Dutch companies.\nMSc thesis For students\nWe have many more students than staff members and thus we cannot guarantee that we can supervise you on any of these topics. Thus, before you contact the company, make sure you have a TU Delft supervisor.\nGet in touch\nFor companies\nPlease provide a PDF with the project including scientific research questions. The PDF will be posted here, and thus advertised to potential students. We cannot guarantee that students respond to the project; we can also not guarantee that someone from the computer vision lab can supervise.\nSubmit proposal\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"58c20df4573b157af6531f3471dd4363","permalink":"https://cvlab-tudelft.github.io/education/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/education/","section":"","summary":"Teaching We provide various courses on computer vision at both the undergraduate and the graduate level. Specifically, we teach courses on Image Processing (B.Sc. level), Computer Vision (M.Sc. level) and Deep Learning (M.","tags":null,"title":"Education","type":"page"},{"authors":null,"categories":null,"content":"Interested in joining us at the Computer Vision lab? Check to see if we have any open vacancies on the TU Delft website.\nVacancies\nInternships\nWe provide the opportunity to join the tab temporarily through internships for PhD candidates from other labs. Contact us through the contact form on the homepage.\nThesis supervision\nPlease see our page on thesis supervision.\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"8235523060c2ddd0daa3e018dcee1928","permalink":"https://cvlab-tudelft.github.io/join/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/join/","section":"","summary":"Interested in joining us at the Computer Vision lab? Check to see if we have any open vacancies on the TU Delft website.\nVacancies\nInternships\nWe provide the opportunity to join the tab temporarily through internships for PhD candidates from other labs.","tags":null,"title":"Join us","type":"page"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"c1d17ff2b20dca0ad6653a3161942b64","permalink":"https://cvlab-tudelft.github.io/people/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/people/","section":"","summary":"","tags":null,"title":"People","type":"widget_page"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"f1d044c0738ab9f19347f15c290a71a1","permalink":"https://cvlab-tudelft.github.io/research/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/research/","section":"","summary":"","tags":null,"title":"Research","type":"widget_page"}]