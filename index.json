[{"authors":["marcel-reinders"],"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"2a1a5c2796f9a0f99b5105cc33e1d60f","permalink":"https://cvlab-tudelft.github.io/people/marcel-reinders/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/people/marcel-reinders/","section":"authors","summary":"","tags":null,"title":"Marcel Reinders","type":"authors"},{"authors":["jan-van-gemert"],"categories":null,"content":"","date":1643527421,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1643527421,"objectID":"b2af85fedca93d0982de0d50ca39785c","permalink":"https://cvlab-tudelft.github.io/people/jan-van-gemert/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/people/jan-van-gemert/","section":"authors","summary":"","tags":null,"title":"Jan van Gemert","type":"authors"},{"authors":["xucong-zhang"],"categories":null,"content":"Research Interest: My current research is about computer vision, machine learning, and human-computer interactions. My core research interest is human-centred computing as developing techniques for sensing, understanding, and serving the human user.\n  Gaze estimation The task is the estimation of where the people looking from the input eye/face image. The methodology is mainly about computer vision and machine learning techniques.\n  Human-computer interaction My current research on HCI is applying the computer vision methods, such as gaze estimation, to the HCI task.\n  Human digitalization My next five years (2022-2027) research plan is to develop the talking virtual avatar that can act like a human being. The virtual avatar can be used for HCI application and human-related modelling.\n  Biomechanical prior model My next ten years (2022 - 2032) research plan is to develop computer vision and machine learning tools for biology- and healthcare-related research. As the starting point, I will introduce the biomechanical prior for the human-related models.\n  Short Bio: I am an assistant professor at TU Delft since August 2021. I was a postdoc researcher (2018-2021) in the Advanced Interaction Technologies Lab at ETH Zurich, led by Prof. Otmar Hilliges. I did my PhD research (2013-2018) at Max Planck Institute for Informatics (MPII) under the supervision of Prof. Andreas Bulling, and received the doctoral degree ( summa cum laude) from Saarland University, Germany.\n","date":1659102979,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1659102979,"objectID":"b65529db56b0913d094fb03d1d5f3a80","permalink":"https://cvlab-tudelft.github.io/people/xucong-zhang/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/people/xucong-zhang/","section":"authors","summary":"Research Interest: My current research is about computer vision, machine learning, and human-computer interactions. My core research interest is human-centred computing as developing techniques for sensing, understanding, and serving the human user.","tags":null,"title":"Xucong Zhang","type":"authors"},{"authors":["nergis-tomen"],"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"bc3258f4c96ba206793bc2ad2e7d76fb","permalink":"https://cvlab-tudelft.github.io/people/nergis-tomen/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/people/nergis-tomen/","section":"authors","summary":"","tags":null,"title":"Nergis Tömen","type":"authors"},{"authors":["hadi-jamali-rad"],"categories":null,"content":"Hadi Jamali-Rad is a lead research scientist with Shell, also a Part-Time Assistant Professor (20%) with the department of intelligent systems (INSY), the Computer Vision Lab, at TU Delft. His research interest lies in the confluence of machine learning and optimization applied to a variety of problems in computer vision, wireless (IoT) networking, and geophysics. He leads the R\u0026amp;D track of deep learning and computer vision at Shell, as well as major projects in the AI space. Prior to joining Shell, he obtained his PhD in statistical signal processing (Cum Laude) under supervision of Prof. Geert Leus at TU Delft in 2014. During his PhD, he visited CSIP at Georgia Tech (supervised by Prof. Xiaoli Ma), and STADIUS at KU Leuven (supervised by Prof. Marc Moonen and dr. Toon van Waterschoot).\nPersonal page: https://sites.google.com/view/jamalirad/\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"9ccb4a3bd16b884c19c69c2b74f4716f","permalink":"https://cvlab-tudelft.github.io/people/hadi-jamali-rad/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/people/hadi-jamali-rad/","section":"authors","summary":"Hadi Jamali-Rad is a lead research scientist with Shell, also a Part-Time Assistant Professor (20%) with the department of intelligent systems (INSY), the Computer Vision Lab, at TU Delft. His research interest lies in the confluence of machine learning and optimization applied to a variety of problems in computer vision, wireless (IoT) networking, and geophysics.","tags":null,"title":"Hadi Jamali-Rad","type":"authors"},{"authors":["robert-jan-bruintjes"],"categories":null,"content":"Third year PhD candidate in the Computer Vision lab at TU Delft, the Netherlands. I am interested in method that integrate prior knowledge about the visual domain into Deep Learning-based Computer Vision. This prior knowledge includes equivariance to geometrical transformations and signal processing best practices. I am a co-organizer of the yearly Visual Inductive Priors for Data-Efficient Deep Learning workshop, hosted at ECCV and ICCV.\n","date":1643527421,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1643527421,"objectID":"29932f6107eb093aead06ece2160a538","permalink":"https://cvlab-tudelft.github.io/people/robert-jan-bruintjes/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/people/robert-jan-bruintjes/","section":"authors","summary":"Third year PhD candidate in the Computer Vision lab at TU Delft, the Netherlands. I am interested in method that integrate prior knowledge about the visual domain into Deep Learning-based Computer Vision.","tags":null,"title":"Robert-Jan Bruintjes","type":"authors"},{"authors":["attila-lengyel"],"categories":null,"content":"Third year PhD Candidate at the Computer Vision Lab of Delft University of Technology. I’m interested in both fundamental deep learning research as well as developing computer vision technology to help tackle today’s global challenges. My main research interests include self-supervised representation learning, invariant / equivariant CNNs and color encoding in neural networks.\nBesides that, I also enjoy (kite)surfing, hiking and playing the guitar.\nIf you’re interested to collaborate, feel free to drop me an email.\n","date":1633817635,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1633817635,"objectID":"408b394be9107c079a4cfb0dca4a7c0b","permalink":"https://cvlab-tudelft.github.io/people/attila-lengyel/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/people/attila-lengyel/","section":"authors","summary":"Third year PhD Candidate at the Computer Vision Lab of Delft University of Technology. I’m interested in both fundamental deep learning research as well as developing computer vision technology to help tackle today’s global challenges.","tags":null,"title":"Attila Lengyel","type":"authors"},{"authors":["silvia-l-pintea"],"categories":null,"content":"Left TU Delft in 2021.\nHomepage: https://silvialaurapintea.github.io/\n","date":1615325726,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1615325726,"objectID":"10c3d710fa54d7500670e27aa2f53f0a","permalink":"https://cvlab-tudelft.github.io/people/silvia-l.-pintea/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/people/silvia-l.-pintea/","section":"authors","summary":"Left TU Delft in 2021.\nHomepage: https://silvialaurapintea.github.io/","tags":null,"title":"Silvia L. Pintea","type":"authors"},{"authors":["xin-liu"],"categories":null,"content":"","date":1615325726,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1615325726,"objectID":"8f6af26f33f152ceddb7334ad2667cf0","permalink":"https://cvlab-tudelft.github.io/people/xin-liu/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/people/xin-liu/","section":"authors","summary":"","tags":null,"title":"Xin Liu","type":"authors"},{"authors":["osman-semih-kayhan"],"categories":null,"content":"","date":1615281981,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1615281981,"objectID":"603eb7bbd72506174cfbe7ead1a94f23","permalink":"https://cvlab-tudelft.github.io/people/osman-semih-kayhan/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/people/osman-semih-kayhan/","section":"authors","summary":"","tags":null,"title":"Osman Semih Kayhan","type":"authors"},{"authors":["yancong-lin"],"categories":null,"content":"","date":1595098203,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1595098203,"objectID":"09bd1a4492f678a84d62ef7c06a6a08c","permalink":"https://cvlab-tudelft.github.io/people/yancong-lin/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/people/yancong-lin/","section":"authors","summary":"","tags":null,"title":"Yancong Lin","type":"authors"},{"authors":["ombretta-strafforello"],"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"a44889352918ad22926ffb049b6d1e99","permalink":"https://cvlab-tudelft.github.io/people/ombretta-strafforello/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/people/ombretta-strafforello/","section":"authors","summary":"","tags":null,"title":"Ombretta Strafforello","type":"authors"},{"authors":["ziqi-wang"],"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"11291476184bee52af0ea63404e69581","permalink":"https://cvlab-tudelft.github.io/people/ziqi-wang/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/people/ziqi-wang/","section":"authors","summary":"","tags":null,"title":"Ziqi Wang","type":"authors"},{"authors":["Xucong Zhang","Seonwook Park","and Anna Maria Feit"],"categories":[],"content":"","date":1659102979,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1659102979,"objectID":"948e0bdc5e60131769b4454a80f7c77c","permalink":"https://cvlab-tudelft.github.io/publication/2021_gaze_and_applications/","publishdate":"2022-07-29T15:56:19+02:00","relpermalink":"/publication/2021_gaze_and_applications/","section":"publication","summary":"The human eye gaze is an important non-verbal cue that can unobtrusively provide information about the intention and attention of a user to enable intelligent interactive systems. Eye gaze can also be taken as input to systems as a replacement of the conventional mouse and keyboard, and can also be indicative of the cognitive state of the user. However, estimating and applying gaze in real-world applications poses significant challenges. In this chapter, we first review the development of gaze estimation methods in recent years. We especially focus on learning-based gaze estimation methods which benefit from large-scale data and deep learning methods that recently became available. Second, we discuss the challenges of using gaze estimation for real-world applications and our efforts toward making these methods easily usable for the Human-Computer Interaction community. At last, we provide two application examples, demonstrating the use of eye gaze to enable attentive and adaptive interfaces.","tags":[],"title":"Eye Gaze Estimation and Its Applications","type":"publication"},{"authors":["David W. Romero","Robert-Jan Bruintjes","Jakub M. Tomczak","Erik J. Bekkers","Mark Hoogendoorn","Jan van Gemert"],"categories":[],"content":"","date":1643527421,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1643527421,"objectID":"cdb49603fa88696470d1544bdc1bf43a","permalink":"https://cvlab-tudelft.github.io/publication/2021-flexconv/","publishdate":"2022-01-30T09:23:41+02:00","relpermalink":"/publication/2021-flexconv/","section":"publication","summary":"We provide a high bandwidth, alias-free convolutional kernel parameterization with learnable kernel size and constant parameter cost.","tags":["inductive priors"],"title":"FlexConv: Continuous Kernel Convolutions with Differentiable Kernel Sizes","type":"publication"},{"authors":["Adrian Spurr*","Aneesh Dahiya*","Xi Wang","Xucong Zhang","and Otmar Hilliges."],"categories":[],"content":"","date":1635516776,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1635516776,"objectID":"cdba4003ac9afef932e223fe8e2b3f61","permalink":"https://cvlab-tudelft.github.io/publication/2021_peclr/","publishdate":"2022-07-29T16:12:56+02:00","relpermalink":"/publication/2021_peclr/","section":"publication","summary":"","tags":[],"title":"Self-Supervised 3D Hand Pose Estimation from monocular RGB via Contrastive Learning","type":"publication"},{"authors":["Attila Lengyel","Sourav Garg","Michael Milford","Jan van Gemert"],"categories":[],"content":"","date":1633817635,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1633817635,"objectID":"a7f6b113ecf52590a6a46894f29add70","permalink":"https://cvlab-tudelft.github.io/publication/2021-zero-shot-day-night/","publishdate":"2021-10-10T00:13:55+02:00","relpermalink":"/publication/2021-zero-shot-day-night/","section":"publication","summary":"We explore the zero-shot setting for day-night domain adaptation. We cast a number of color invariant edge detectors as trainable layers in a convolutional neural network and evaluate their robustness to illumination changes.","tags":["ICCV","color invariants","domain adaptation","day-night"],"title":"Zero-Shot Day-Night Domain Adaptation with a Physics Prior","type":"publication"},{"authors":["Attila Lengyel","Jan van Gemert"],"categories":[],"content":"","date":1631227226,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1631227226,"objectID":"cf6251c884e6365de06b0bafa0a4fd06","permalink":"https://cvlab-tudelft.github.io/publication/2021-separable-gconv/","publishdate":"2021-10-10T00:40:26+02:00","relpermalink":"/publication/2021-separable-gconv/","section":"publication","summary":"We show that GConvs can be efficiently decomposed into depthwise separable convolutions while preserving equivariance properties and demonstrate improved performance and data efficiency on two datasets.","tags":["ICIP","equivariance","gconv","data efficiency"],"title":"Exploiting Learned Symmetries in Group Equivariant Convolutions","type":"publication"},{"authors":["Xin Liu","Silvia L. Pintea","Fatemeh Karimi Nejadasl","Olaf Booij","Jan van Gemert"],"categories":[],"content":"","date":1615325726,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1615325726,"objectID":"af6eb57e329c30d7c441cb32d544d215","permalink":"https://cvlab-tudelft.github.io/publication/2021-no-frame-left-behind/","publishdate":"2021-03-09T23:35:26+02:00","relpermalink":"/publication/2021-no-frame-left-behind/","section":"publication","summary":"We cluster video frames end-to-end to use all frames in action recognition.","tags":["video-understanding"],"title":"No frame left behind: Full Video Action Recognition","type":"publication"},{"authors":["Robert-Jan Bruintjes","Attila Lengyel","Marcos Baptista Rios","Osman Semih Kayhan","Jan van Gemert"],"categories":[],"content":"","date":1615281981,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1615281981,"objectID":"4c0824bc0d51e476b3716d85ced5012c","permalink":"https://cvlab-tudelft.github.io/publication/2021-vipriors-1/","publishdate":"2021-03-09T10:26:21+01:00","relpermalink":"/publication/2021-vipriors-1/","section":"publication","summary":"We present the first edition of \"VIPriors: Visual Inductive Priors for Data-Efficient Deep Learning\" challenges. We offer four data-impaired challenges to encourage data efficient solutions.","tags":["inductive priors"],"title":"VIPriors 1: Visual Inductive Priors for Data-Efficient Deep Learning Challenges","type":"publication"},{"authors":[],"categories":[],"content":"","date":1596530978,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1596530978,"objectID":"9f03df6f49931228b586d9fa8e62bb1b","permalink":"https://cvlab-tudelft.github.io/publication/2020_sted/","publishdate":"2022-08-04T10:49:38+02:00","relpermalink":"/publication/2020_sted/","section":"publication","summary":"","tags":[],"title":"Self-Learning Transformations for Improving Gaze and Head Redirection","type":"publication"},{"authors":["Yancong Lin","Silvia L. Pintea","Jan van Gemert"],"categories":[],"content":"","date":1595098203,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1595098203,"objectID":"53248486837ba72de91b53d420b70488","permalink":"https://cvlab-tudelft.github.io/publication/2020-deep-hough/","publishdate":"2020-09-11T20:50:03+02:00","relpermalink":"/publication/2020-deep-hough/","section":"publication","summary":"We add line priors through a trainable Hough transform block into a deep network.","tags":["Hough transform","inductive priors","line detection"],"title":"Deep Hough-Transform Line Priors","type":"publication"},{"authors":["Osman Semih Kayhan","Jan van Gemert"],"categories":[],"content":"","date":1583597647,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1583597647,"objectID":"33c3056fabefb6e8866005ef9dc68f29","permalink":"https://cvlab-tudelft.github.io/publication/2020-on-translation-invariance/","publishdate":"2020-09-07T18:14:07+02:00","relpermalink":"/publication/2020-on-translation-invariance/","section":"publication","summary":"We show we can prevent CNNs from exploiting absolute location through image boundary effects.","tags":["inductive priors","equivariance","boundary effects","image classification"],"title":"On Translation Invariance in CNNs: Convolutional Layers Can Exploit Absolute Spatial Location","type":"publication"},{"authors":null,"categories":null,"content":"Teaching We provide various courses on computer vision at both the undergraduate and the graduate level. Specifically, we teach courses on Image Processing (B.Sc. level), Computer Vision (M.Sc. level) and Deep Learning (M.Sc. level). In addition, we supervise students at all levels in fundamental and applied research projects, several of which are performed in collaboration with Dutch companies.\nMSc thesis For students\nWe have many more students than staff members and thus we cannot guarantee that we can supervise you on any of these topics. Thus, before you contact the company, make sure you have a TU Delft supervisor.\nGet in touch\nFor companies\nPlease provide a PDF with the project including scientific research questions. The PDF will be posted here, and thus advertised to potential students. We cannot guarantee that students respond to the project; we can also not guarantee that someone from the computer vision lab can supervise.\nSubmit proposal\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"58c20df4573b157af6531f3471dd4363","permalink":"https://cvlab-tudelft.github.io/education/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/education/","section":"","summary":"Teaching We provide various courses on computer vision at both the undergraduate and the graduate level. Specifically, we teach courses on Image Processing (B.Sc. level), Computer Vision (M.Sc. level) and Deep Learning (M.","tags":null,"title":"Education","type":"page"},{"authors":null,"categories":null,"content":"Interested in joining us at the Computer Vision lab? Check to see if we have any open vacancies on the TU Delft website.\nVacancies\nInternships\nWe provide the opportunity to join the tab temporarily through internships for PhD candidates from other labs. Contact us through the contact form on the homepage.\nThesis supervision\nPlease see our page on thesis supervision.\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"8235523060c2ddd0daa3e018dcee1928","permalink":"https://cvlab-tudelft.github.io/join/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/join/","section":"","summary":"Interested in joining us at the Computer Vision lab? Check to see if we have any open vacancies on the TU Delft website.\nVacancies\nInternships\nWe provide the opportunity to join the tab temporarily through internships for PhD candidates from other labs.","tags":null,"title":"Join us","type":"page"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"c1d17ff2b20dca0ad6653a3161942b64","permalink":"https://cvlab-tudelft.github.io/people/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/people/","section":"","summary":"","tags":null,"title":"People","type":"widget_page"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"f1d044c0738ab9f19347f15c290a71a1","permalink":"https://cvlab-tudelft.github.io/research/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/research/","section":"","summary":"","tags":null,"title":"Research","type":"widget_page"}]